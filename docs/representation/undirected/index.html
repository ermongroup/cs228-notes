<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Markov random fields</title>
  <meta name="description" content="Lecture notes for Stanford cs228.">


  <link rel="stylesheet" href="/cs228-notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/cs228-notes/representation/undirected/">
  <link rel="alternate" type="application/rss+xml" title="Probabilistic graphical modeling course" href="http://localhost:4000/cs228-notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/cs228-notes/">Contents</a>
	<a href="http://cs.stanford.edu/~ermon/cs228/index.html">Class</a>
	<a href="http://github.com/ermongroup/cs228-notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Markov random fields</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<p>Bayesian networks are a class of models that can compactly represent many interesting probability distributions. However, we have seen in the previous chapter that some distributions cannot be perfectly represented by a Bayesian network.</p>

<p>In such cases, unless we want to introduce false independencies among the variables of our model, we must fall back to a less compact representation (which can be viewed as a graph with additional, unnecessary edges). This leads to extra, unnecessary parameters in the model, and makes it more difficult to learn these parameters and to make predictions.</p>

<p>There exists, however, another technique for compactly representing and visualizing a probability distribution that is based on the language of <em>undirected</em> graphs. This class of models (known as Markov Random Fields or MRFs) can compactly represent distributions that directed models cannot represent. We will explore the advantages and drawbacks of these methods in this chapter.</p>

<h2 id="markov-random-fields">Markov Random Fields</h2>

<p><label for="nb1" class="margin-toggle">⊕</label><input type="checkbox" id="nb1" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/cs228-notes/assets/img/mrf.png" /><br />Undirected graphical representation of a joint probability of voting preferences over four individuals. The figure on the right illustrates the pairwise factors present in the model.</span> As a motivating example, suppose that we are modeling voting preferences among persons <script type="math/tex">A,B,C,D</script>. Let’s say that <script type="math/tex">(A,B)</script>, <script type="math/tex">(B,C)</script>, <script type="math/tex">(C,D)</script>, and <script type="math/tex">(D,A)</script> are friends, and friends tend to have similar voting preferences. These influences can be naturally represented by an undirected graph.</p>

<p>One way to define a probability over the joint voting decision of <script type="math/tex">A,B,C,D</script> is to assign scores to each assignment to these variables and then define a probability as a normalized score. A score can be any function, but in our case, we will define it to be of the form</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
\tilde p(A,B,C,D) = \phi(A,B)\phi(B,C)\phi(C,D)\phi(D,A), 
</script></div>
<p>where <script type="math/tex">\phi(X,Y)</script> is a factor that assigns more weight to consistent votes among friends <script type="math/tex">X,Y</script>, e.g.:</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
\begin{align*}
\phi(X,Y) = 
\begin{cases}
10 & \text{ if}\; X = Y = 1 \\
5 & \text{ if}\; X = Y = 0 \\
1 & \text{ otherwise}.
\end{cases}
\end{align*}
</script></div>
<p>The factors in the unnormalized distribution are often referred to as <em>potentials</em>.
The final probability is then defined as</p>
<div class="mathblock"><script type="math/tex; mode=display">
p(A,B,C,D) = \frac{1}{Z} \tilde p(A,B,C,D),
</script></div>
<p>where <script type="math/tex">Z = \sum_{A,B,C,D} \tilde p(A,B,C,D)</script> is a normalizing constant that ensures that the distribution sums to one.</p>

<p>When normalized, we can view <script type="math/tex">\phi(A,B)</script> as an interaction that pushes <script type="math/tex">B</script>’s vote closer to that of <script type="math/tex">A</script>. The term <script type="math/tex">\phi(B,C)</script> pushes <script type="math/tex">B</script>’s vote closer to <script type="math/tex">C</script>, and the most likely vote will require reconciling these conflicting influences.</p>

<p>Note that unlike in the directed case, we are not saying anything about how one variable is generated from another set of variables (as a conditional probability distribution would do). We simply indicate a level of coupling between dependent variables in the graph. In a sense, this requires less prior knowledge, as we no longer have to specify a full generative story of how the vote of <script type="math/tex">B</script> is constructed from the vote of <script type="math/tex">A</script> (which we would need to do if we had a <script type="math/tex">P(B\mid A)</script> factor). Instead, we simply identify dependent variables and define the strength of their interactions; this in turn defines an energy landscape over the space of possible assignments and we convert this energy to a probability via the normalization constant.</p>

<h3 id="formal-definition">Formal definition</h3>

<p>A Markov Random Field (MRF) is a probability distribution <script type="math/tex">p</script> over variables <script type="math/tex">x_1,...,x_n</script> defined by an <em>undirected</em> graph <script type="math/tex">G</script> in which nodes correspond to variables <script type="math/tex">x_i</script>. The probability <script type="math/tex">p</script>
has the form</p>
<div class="mathblock"><script type="math/tex; mode=display">
p(x_1,..,x_n) = \frac{1}{Z} \prod_{c \in C} \phi_c(x_c),
</script></div>
<p>where <script type="math/tex">C</script> denotes the set of <em>cliques</em> (i.e. fully connected subgraphs) of <script type="math/tex">G</script>.
The value</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
Z = \sum_{x_1,..,x_n}\prod_{c \in C} \phi_c(x_c) 
</script></div>
<p>is a normalizing constant that ensures that the distribution sums to one.</p>

<p>Thus, given a graph <script type="math/tex">G</script>, our probability distribution may contain factors whose scope is any clique in <script type="math/tex">G</script>, which can be a single node, an edge, a triangle, etc. Note that we do not need to specify a factor for each clique. In our above example, we defined a factor over each edge (which is a clique of two nodes). However, we chose not to specify any unary potentials i.e. cliques over single nodes.</p>

<h3 id="comparison-to-bayesian-networks">Comparison to Bayesian networks</h3>

<p><label for="nb1" class="margin-toggle">⊕</label><input type="checkbox" id="nb1" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/cs228-notes/assets/img/mrf2.png" /><br />Examples of directed models for our four-variable voting example. None of them can accurately express our prior knowledge about the dependency structure among the variables.</span>
In our earlier voting example, we had a distribution over <script type="math/tex">A,B,C,D</script> that satisfied <script type="math/tex">A \perp C \mid  \{B,D\}</script> and <script type="math/tex">B \perp D \mid  \{A,C\}</script> (because only friends directly influence a person’s vote). We can easily check by counter-example that these independencies cannot be perfectly represented by a Bayesian network.
However, the MRF turns out to a perfect map for this distribution.</p>

<p>More generally, MRFs have several advantages over directed models:</p>

<ul>
  <li>They can be applied to a wider range of problems in which there is no natural directionality associated with variable dependencies.</li>
  <li>Undirected graphs can succinctly express certain dependencies that Bayesian nets cannot easily describe (although the converse is also true)</li>
</ul>

<p>They also possess several important drawbacks:</p>

<ul>
  <li>Computing the normalization constant <script type="math/tex">Z</script> requires summing over a potentially exponential number of assignments. We will see that in the general case, this will be NP-hard; thus many undirected models will be intractable and will require approximation techniques.</li>
  <li>Undirected models may be difficult to interpret.</li>
  <li>It is much easier to generate data from a Bayesian network, which is important in some applications.</li>
</ul>

<p>It is not hard to see that Bayesian networks are a special case of MRFs with a very specific type of clique potential (one that corresponds to a conditional probability distribution and implies a directed acyclic structure in the graph), and a normalizing constant of one. In particular, if we take a directed graph <script type="math/tex">G</script> and add side edges to all parents of a given node (and removing their directionality), then the CPDs (seen as factors over a variable and its ancestors) factorize over the resulting undirected graph. The resulting process is called <em>moralization</em>.</p>
<figure><figcaption>A Bayesian network can always be converted into an undirected network with normalization constant one. The converse is also possible, but may be computationally intractable, and may produce a very large (e.g. fully connected) directed graph.</figcaption><img src="/cs228-notes/assets/img/moralization.png" /></figure>

<p>Thus, MRFs have more power than Bayesian networks, but are more difficult to deal with computationally. A general rule of thumb is to use Bayesian networks whenever possible, and only switch to MRFs if there is no natural way to model the problem with a directed graph (like in our voting example).</p>

<h2 id="independencies-in-markov-random-fields">Independencies in Markov Random Fields</h2>

<p>Recall that in the case of Bayesian networks, we defined a set of independencies <script type="math/tex">I(G)</script> that were described by a directed graph <script type="math/tex">G</script>, and showed how these describe true independencies that must hold in a distribution <script type="math/tex">p</script> that factorizes over the directed graph, i.e. <script type="math/tex">I(G) \subseteq I(p)</script>.</p>

<p><label for="markovblanket" class="margin-toggle">⊕</label><input type="checkbox" id="markovblanket" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/cs228-notes/assets/img/markovblanket.png" /><br />In an MRF, a node <script type="math/tex">X</script> is independent from the rest of the graph given its neighbors (which are reffered to at the Markov blanket of <script type="math/tex">X</script>.</span> 
What independencies can be then described by an undirected MRF? The answer here is very simple and intuitive: variables <script type="math/tex">x,y</script> are dependent if they are connected by a path of unobserved variables. However, if <script type="math/tex">x</script>’s neighbors are all observed, then <script type="math/tex">x</script> is independent of all the other variables, since they influence <script type="math/tex">x</script> only via its neighbors.</p>

<p>In particular, if a set of observed variables forms a cutset between two halves of the graph, then variables in one half are independent from ones in the other.</p>

<figure><figcaption></figcaption><img src="/cs228-notes/assets/img/cutset.png" /></figure>

<p>Formally, we define the <em>Markov blanket</em> <script type="math/tex">U</script> of a variable <script type="math/tex">X</script> as the minimal set of nodes such that <script type="math/tex">X</script> is independent from the rest of the graph if <script type="math/tex">U</script> is observed, i.e. <script type="math/tex">X \perp (\mathcal{X} - \{X\} - U) \mid  U</script>. This notion holds for both directed and undirected models, but in the undirected case the Markov blanket turns out to simply equal a node’s neighborhood.</p>

<p>In the directed case, we found that <script type="math/tex">I(G) \subseteq I(p)</script>, but there were distributions <script type="math/tex">p</script> whose independencies could not be described by <script type="math/tex">G</script>. In the undirected case, the same holds. For example, consider a probability described by a directed v-structure (i.e. the explaining away phenomenon). The undirected model cannot describe the independence assumption <script type="math/tex">X \perp Y</script>.</p>

<figure><figcaption>Examples of probability distributions that have a perfect directed graphical representation but no undirected representation, and vice-versa.</figcaption><img src="/cs228-notes/assets/img/mrf-bn-comparison.png" /></figure>

<h2 id="conditional-random-fields">Conditional Random Fields</h2>

<p>An important special case of Markov Random Fields arises when they are applied to model a conditional probability distribution <script type="math/tex">p(y\mid x)</script>. In this case, <script type="math/tex">x \in \mathcal{X}</script> and <script type="math/tex">y \in \mathcal{Y}</script> are vector-valued variables; we are typically given <script type="math/tex">x</script> and want to say something interesting for <script type="math/tex">y</script>. Typically, distributions of this sort will arise in a supervised learning setting, where <script type="math/tex">y</script> will be a vector-valued label that we will be trying to predict. This setting is typically referred to as <em>structured prediction</em>.</p>

<h3 id="example">Example</h3>

<p>As a motivating example, consider the problem of recognizing a word from a sequence of character images <script type="math/tex">x_i \in [0, 1]^{d\times d}</script> given to us in the form of pixel matrices. The output of our predictor will be a sequence of alphabet letters <script type="math/tex">y_i \in \{'a','b',...,'z'\}</script>.</p>

<figure><figcaption>Chain-structured conditional random field for optical character recognition.</figcaption><img src="/cs228-notes/assets/img/ocr.png" /></figure>

<p>We could in principle train a classifier to separately predict each <script type="math/tex">y_i</script>  from its <script type="math/tex">x_i</script>. However, since the letters together form a word, the predictions across different <script type="math/tex">i</script> ought to inform each other. In the above example, the second letter by itself could be either a ’U’ or a ’V’; however, since we can tell with high confidence that its neighbors are ’Q’ and ’E’, we can infer that ’U’ is the most likely true label. CRFs will be a tool that will enable us to perform this prediction jointly.</p>

<h3 id="formal-definition-1">Formal definition</h3>

<p>Formally, a CRF is a Markov network over variables <script type="math/tex">\mathcal X \cup \mathcal Y</script> which specifies a conditional distribution</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
P(y\mid x) = \frac{1}{Z(x)} \prod_{c \in C} \phi_c(x_c,y_c) 
</script></div>
<p>with partition function</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
Z(x) = \sum_{y \in \mathcal{Y}} \prod_{c \in C} \phi_c(x_c,y_c). 
</script></div>

<p>Note that in this case, the partition constant now depends on <script type="math/tex">x</script> (therefore, we say that it is a function), which is not surprising: <script type="math/tex">p(y\mid x)</script> is a probability over <script type="math/tex">y</script> that is parametrized by <script type="math/tex">x</script>, i.e. it encodes a different probability function for each <script type="math/tex">x</script>. In that sense, a conditional random field results in an instantiation of a new Markov Random Field for each input <script type="math/tex">x</script>.</p>

<h3 id="example-continued">Example (continued)</h3>

<p>More formally, suppose <script type="math/tex">p(y\mid x)</script> is a chain CRF with two types of potentials: image potentials <script type="math/tex">\phi(x_i, y_i)</script> for <script type="math/tex">i = 1, ..., n</script> — which assign higher values to <script type="math/tex">y_i</script> that are consistent with an input <script type="math/tex">x_i</script> — as well as pairwise potentials <script type="math/tex">\phi(y_i, y_{i+1})</script> for <script type="math/tex">i = 1, ..., n-1</script>. We may also think of the <script type="math/tex">\phi(x_i,y_i)</script> as probabilities <script type="math/tex">p(y_i\mid x_i)</script> given by, say, standard (unstructured) softmax regression; the <script type="math/tex">\phi(y_i, y_{i+1})</script> can be seen as empirical frequencies of letter co-occurrences obtained from a large corpus of English text (e.g. Wikipedia).</p>

<p>Given a model of this form, we can jointly infer the structured label <script type="math/tex">y</script> using MAP inference:</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
\arg \max_y \phi_1(y_1, x_1) \prod_{i=2}^n \phi(y_{i-1}, y_i) \phi(y_i, x_i). 
</script></div>

<h3 id="crf-features">CRF features</h3>

<p>In most practical applications, we further assume that the potentials <script type="math/tex">\phi_c(x_c,y_c)</script> are of the form</p>
<div class="mathblock"><script type="math/tex; mode=display">
\phi_c(x_c,y_c) = \exp(w_c^T f_c(x_c, y_c)),
</script></div>
<p>where <script type="math/tex">f_c(x_c, y_c)</script> can be an arbitrary set of features describing the compatibility between <script type="math/tex">x_c</script> and <script type="math/tex">y_c</script>.</p>

<p>In our OCR example, we may introduce features <script type="math/tex">f(x_i, y_i)</script>; that encode the compatibility of the letter <script type="math/tex">y_i</script> with the pixels <script type="math/tex">x_i</script>. For example, <script type="math/tex">f(x_i, y_i)</script>; may be the probability of letter <script type="math/tex">y_i</script> produced by logistic regression (or a deep neural network) evaluated on pixels <script type="math/tex">x_i</script>. In addition, we introduce features <script type="math/tex">f(y_i, y_{i+1})</script> between adjacent letters. These may be indicators of the form <script type="math/tex">f(y_i, y_{i+1}) = \Ind(y_i = \ell_1, y_{i+1} = \ell_2)</script>, where <script type="math/tex">\ell_1, \ell_2</script> are two letters of the alphabet. The CRF would then learn weights <script type="math/tex">w</script> that would assign more weight to more common probability of consecutive letters <script type="math/tex">(\ell_1, \ell_2)</script>, while at the same time making sure that the predicted <script type="math/tex">y_i</script> are consistent with the input <script type="math/tex">x_i</script>; this process would let us determine <script type="math/tex">y_i</script> in cases where <script type="math/tex">x_i</script> is ambiguous, like in our above example.</p>

<p>The most important realization that need to be made about CRF features is that they can be arbitrarily complex. In fact, we may define an OCR model with potentials <script type="math/tex">\phi_i(x,y_i) = \exp(w_i^T f(x, y_i))</script>, that depend on the entire input <script type="math/tex">x</script>. This will not affect computational performance at all, because at inference time, the <script type="math/tex">x</script> will be always observed, and our decoding problem will involve maximizing</p>
<div class="mathblock"><script type="math/tex; mode=display"> 
\phi_1(y_1, x) \prod_{i=2}^n \phi(y_{i-1}, y_i) \phi(y_i, x) = \phi_1'(y_1) \prod_{i=2}^n \phi(y_{i-1}, y_i) \phi'(y_i),
</script></div>
<p>where <script type="math/tex">\phi'_i(y_i) = \phi_i(x,y_i)</script>. Using global features only changes the values of the factors, but not their scope, which possesses the same type of chain structure. We will see in the next section that this structure is all that is needed to ensure we can solve this optimization problem tractably.</p>

<p>This observation may be interpreted in a slightly more general form. If we were to model <script type="math/tex">p(x,y)</script> using an MRF (viewed as a single model over <script type="math/tex">x, y</script> with normalizing constant <script type="math/tex">Z = \sum_{x,y} \tp(x,y)</script>), then we need to fit two distributions to the data: <script type="math/tex">p(y\mid x)</script> and <script type="math/tex">p(x)</script>. However, if all we are interested in is predicting <script type="math/tex">y</script> given <script type="math/tex">x</script>, then modeling <script type="math/tex">p(x)</script> is unnecessary. In fact, it may be disadvantageous to do so statistically (e.g. we may not have enough data to fit both <script type="math/tex">p(y\mid x)</script> and <script type="math/tex">p(x)</script>; since the models have shared parameters, fitting one may result in the best parameters for the other) and it may not be a good idea computationally (we need to make simplifying assumptions in the distribution so that <script type="math/tex">p(x)</script> can be handled tractably). CRFs forgo of this assumption, and often perform better on prediction tasks.</p>

<p><br /></p>

<table>
  <tbody>
    <tr>
      <td><a href="../../">Index</a></td>
      <td><a href="../directed">Previous</a></td>
      <td><a href="../../inference/ve">Next</a></td>
    </tr>
  </tbody>
</table>



    </article>
    <span class="print-footer">Markov random fields - Volodymyr Kuleshov</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2017 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;VOLODYMYR KULESHOV &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2017</span> 
</div>  
</footer>

  </body>
</html>
